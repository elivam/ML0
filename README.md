# Метрические алгоритмы классификации
##  Алгоритм k-ближайших соседей                                  
### Метод 1: Метод ближайшего соседа (1nn)
Алгоритм ближайшего соседа (nearest neighbor, NN) является самым простым
алгоритмом классификации. Он относит классифицируемый объект u к тому
классу, которому принадлежит ближайший обучающий объект:

![alt text](https://github.com/elivam/ML0/blob/master/pictures/1nnFormula.PNG), 

где а - это алгоритм, $X^l$ - обучающая выборка, u - классифицирцемый объект, 
$y_u^(1)$ - класс, которому алгоритм дает предпочтение при классификации объекта u

Обучение NN сводится к запоминанию выборки.

 **вход :** 
 
 Xl: matrix 
     обучающая выборка, на последнем месте метка класса;
	 
 u:  vector
     классифицираемый объект;
	 
 q : расстояние
     определить функцию расстояния;
 
 **выход:** имя класса
 
 **Сам алгоритм:**
 1. нахожу расстояние от точки u до точек из выборки, образуя новый вектор
 2. нахожу минимальное расстояние в векторе и запоминаю точку А
 3. узнаю какому классу принадлежит эта точка А и точку u окрашиваю в тот  же класс, какому принадлежит точка А
    
 На языке R алгоритм реализован следующим образом :
 [1NN.R](https://github.com/elivam/ML0/blob/master/1NN/1NN.R)
 
 ![alt text](https://github.com/elivam/ML0/blob/master/pictures/1nn.PNG)
 ### Задача 2: Задача k ближайших соседа (knn)
 Чтобы сгладить
влияние шумовых выбросов, будем классифицировать объекты путём голосования
по k ближайшим соседям.


![alt text](https://github.com/elivam/ML0/blob/master/pictures/knnFormula.PNG)
 
 **вход :** 
 
 Xl: matrix 
     обучающая выборка, на последнем месте метка класса
	 
 u:  vector
     классифицираемый объект
	 
 q : расстояниe
     определить функцию расстояния
	 
 k:  кол-во соседей
     определять кол-во требуемых соседей по LOO для оптимальности алгоритма 
	 
 **выход** имя класса
 
 Сам Алгоритм
 1. нахожу расстояния от точки u до k-ближайших-соседей образуя новый массив, 
   где будет записан класс этой k-точки-соседа и расстояние 
 2. сортирую этот массив 
 3. считаю какие классы соседей встречаются и даю предпочтение тому классу, который наболее частов встречается
     
 На языке R алгоритм реализован следующим образом :
 [kNN.R](https://github.com/elivam/ML0/blob/master/task1/knnShiny.R)
 
 ![alt text](https://github.com/elivam/ML0/blob/master/pictures/knn.PNG)
 
  ### Задача 3: Найти оптимальное кол-во соседей методом LOO
  При k = 1 этот алгоритм совпадает с предыдущим, следовательно, неустойчив
к шуму. При k = ℓ, наоборот, он чрезмерно устойчив и вырождается в константу.
Таким образом, крайние значения k нежелательны. На практике оптимальное значение параметра k определяют по критерию скользящего контроля с исключением
объектов по одному (leave-one-out, LOO). Для каждого объекта xi  проверяется,
правильно ли он классифицируется по своим k ближайшим соседям
  
  ![alt text](https://github.com/elivam/ML0/blob/master/pictures/LOOFormula.PNG) 
  
 **вход :** 
 Xl: matrix 
     обучающая выборка, на последнем месте метка класса
 k:  кол-во соседей
     определять кол-во требуемых соседей по LOO для оптимальности алгоритма 
	 
 **выход** k, при котором допускается наименьшая ошибка   
 На языке R алгоритм реализован следующим образом :
 [kNN and LOO.R](https://github.com/elivam/ML0/blob/master/task1/kNNLOO.R)
 ![alt text](https://github.com/elivam/ML0/blob/master/pictures/knnLoo.PNG) 
 
 Далее построим карту классификации для метода kNN:
 [classMapkNN.R](https://github.com/elivam/ML0/blob/master/task1/classMapkNN.R)
  ![alt text](https://github.com/elivam/ML0/blob/master/pictures/classMapkNN.PNG)
  ### Задача 4: Алгоритм k-взвешенных ближайших соседей
  
   Недостаток kNN в том, что максимальная сумма голосов может достигаться на нескольких классах одновременно.
В задачах с двумя классами этого можно избежать, если брать только нечётные значения k. Более общая тактика, которая годится и для случая многих классов — ввести
строго убывающую последовательность вещественных весов wi, задающих вклад i-го соседа в классификацию

  ![alt text](https://github.com/elivam/ML0/blob/master/pictures/kwnnFormula.PNG)
 
    
 На языке R алгоритм реализован следующим образом :
 [kwNN.R](https://github.com/elivam/ML0/blob/master/task1/kwn.R)
 ![alt text](https://github.com/elivam/ML0/blob/master/pictures/kwnn.PNG)
 
 Далее построим карту классификации для метода kNN:
 
 На языке R алгоритм реализован следующим образом :
 [classMapkwNN.R](https://github.com/elivam/ML0/blob/master/task1/classMapkwNN.R)
 ![alt text](https://github.com/elivam/ML0/blob/master/pictures/classMapkwNN.PNG)
 
  Недостаток kNN в том, что максимальная сумма голосов может достигаться на нескольких классах одновременно. И тогда не понятно какой 
 класс выбирать. Приведем пример.